{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Logo_DuocUC.svg/2560px-Logo_DuocUC.svg.png' width=50%, height=20%>"
      ],
      "metadata": {
        "id": "WPBQlJAv7y6z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2-RSFxG2hB-"
      },
      "source": [
        "# Árboles de decisión\n",
        "\n",
        "Los árboles de decisión son métodos de aprendizaje de máquinas muy utilizados debido a su buen rendimiento y su explicabilidad. Un árbol de decisión no siempre tiene buen rendimiento, por lo que se proponen técnicas de ensamble de árboles de decisión aislados para generar un estimador más robusto que el estimador único por el que está conformado el ensamble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c4l7Gi12hCH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.tree # Árboles de decisión\n",
        "import sklearn.ensemble # Ensambles de modelos\n",
        "import sklearn.model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3iGmeA_2hCI"
      },
      "source": [
        "Utilizaremos un conjunto de datos de predicción de diabetes dado una serie de parámetros fisiológicos de un paciente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9hPyNBl2hCI"
      },
      "outputs": [],
      "source": [
        "diabetes = pd.read_csv(\"data/diabetes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ucFbsO1I2hCJ"
      },
      "outputs": [],
      "source": [
        "diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9_jzcbV2hCJ"
      },
      "source": [
        "Para ilustrar la construcción de un árbol de decisión utilizaremos sólo un par de variables del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q76_c4qi2hCK"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(\n",
        "    data = diabetes,\n",
        "    x = \"Glucose\",\n",
        "    y = \"BMI\",\n",
        "    hue = \"Outcome\",\n",
        "    alpha = 0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osQokeN82hCK"
      },
      "source": [
        "# Árbol de decisión\n",
        "\n",
        "Para la construcción de un árbol de decisión, primero debemos definir una métrica a optimizar. En el caso de los árboles de decisión, una métrica que podemos optimizar es la entropía. En donde a medida que vamos tomando decisiones buscamos ganar información o disminuir la entropía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1ympNkR2hCK"
      },
      "source": [
        "La definición de entropía que utilizaremos es la siguiente:\n",
        "\n",
        "$$\n",
        "H(X)=- \\sum_{i}p(x_i) \\log_2 p(x_i)\n",
        "$$\n",
        "\n",
        "Donde $X$ es el conjunto de etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UWTa2FH2hCL"
      },
      "outputs": [],
      "source": [
        "def entropy(data):\n",
        "    classes = np.unique(data)\n",
        "    entropies = []\n",
        "    for c in classes:\n",
        "        p = sum(data == c) / len(data)\n",
        "        current_entropy = p * np.log2(p)\n",
        "        entropies.append(current_entropy)\n",
        "    return -1 * sum(entropies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzrNiVK_2hCL"
      },
      "source": [
        "Para comenzar, podemos estimar la entropía total del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPSURZm52hCL"
      },
      "outputs": [],
      "source": [
        "entropy(diabetes.Outcome)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gKFgF5a2hCL"
      },
      "source": [
        "Ahora, debemos tomar una decisión, con la cual buscamos disminuir la entropía de cada uno de los subconjuntos obtenidos posterior a la decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icy_kniX2hCM"
      },
      "outputs": [],
      "source": [
        "entropy(diabetes.Outcome[diabetes.Glucose >= 175])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecqKNpmI2hCM"
      },
      "outputs": [],
      "source": [
        "entropy(diabetes.Outcome[diabetes.Glucose < 175])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zhaB3P2hCM"
      },
      "source": [
        "Para estimar la entropía general de la decisión que tomamos debemos calcular un promedio ponderado de cada una de las entropías de cada subconjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK1foaHT2hCN"
      },
      "outputs": [],
      "source": [
        "def weighted_entropy(data, feature, label, threshold):\n",
        "    indices = data[feature] >= threshold\n",
        "    entropy_0 = entropy(data[label][indices])\n",
        "    entropy_1 = entropy(data[label][~indices])\n",
        "    return entropy_0 * (sum(indices) / len(indices)) + entropy_1 * (sum(~indices) / len(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxNJTXNl2hCN"
      },
      "outputs": [],
      "source": [
        "weighted_entropy(diabetes, \"Glucose\", \"Outcome\", 175)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssuMKyxd2hCO"
      },
      "source": [
        "Para determinar la mejor variable y el mejor umbral para la decisión del nodo del árbol debemos optimizar la ganancia de información de la decisión con la siguiente definición:\n",
        "\n",
        "$$\n",
        "IG(Y,X) = E(Y) - E(Y|X)\n",
        "$$\n",
        "\n",
        "Donde a la entropía total del conjunto de datos $E(Y)$ le restamos la entropía promedio $E(Y|X)$ de la decisión $Y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2KluKM02hCP"
      },
      "outputs": [],
      "source": [
        "entropy(diabetes.Outcome) - weighted_entropy(diabetes, \"Glucose\", \"Outcome\", 175)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSlOZlBi2hCR"
      },
      "source": [
        "Calculamos las entropías asociadas a un barrido de umbrales en un par de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-oIIubr2hCS"
      },
      "outputs": [],
      "source": [
        "glucose_information_gain_sweep = []\n",
        "glucose_thresholds = np.linspace(diabetes.Glucose.min(), diabetes.Glucose.max(), 100)\n",
        "for threshold in glucose_thresholds:\n",
        "    glucose_information_gain_sweep.append(entropy(diabetes.Outcome) - weighted_entropy(diabetes, \"Glucose\", \"Outcome\", threshold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Go5v3g2hCT"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(\n",
        "    x = glucose_thresholds,\n",
        "    y = glucose_information_gain_sweep\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQZNjr8U2hCU"
      },
      "outputs": [],
      "source": [
        "bmi_information_gain_sweep = []\n",
        "bmi_thresholds = np.linspace(diabetes.BMI.min(), diabetes.BMI.max(), 100)\n",
        "for threshold in bmi_thresholds:\n",
        "    bmi_information_gain_sweep.append(entropy(diabetes.Outcome) - weighted_entropy(diabetes, \"BMI\", \"Outcome\", threshold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ-5Sl762hCU"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(\n",
        "    x = bmi_thresholds,\n",
        "    y = bmi_information_gain_sweep\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmvrgnQq2hCV"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1,ncols=2, sharey=True)\n",
        "sns.lineplot(\n",
        "    x = glucose_thresholds,\n",
        "    y = glucose_information_gain_sweep,\n",
        "    ax = axs[0]\n",
        ")\n",
        "sns.lineplot(\n",
        "    x = bmi_thresholds,\n",
        "    y = bmi_information_gain_sweep,\n",
        "    ax = axs[1]\n",
        ")\n",
        "axs[0].set_title(\"glucose\")\n",
        "axs[1].set_title(\"bmi\")\n",
        "axs[0].set_ylabel(\"information_gain\")\n",
        "axs[0].set_xlabel(\"threshold\")\n",
        "axs[1].set_xlabel(\"threshold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPk51u42hCV"
      },
      "source": [
        "Seleccionamos el umbral que nos aporta la mayor ganancia de información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03oot6-o2hCV",
        "outputId": "c63ec1e8-816d-4f70-9297-0ffea01dc31f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "124.62626262626262"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimal_glucose_threshold = glucose_thresholds[np.argmax(glucose_information_gain_sweep)]\n",
        "optimal_glucose_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGB2tahP2hCW",
        "outputId": "9c07700d-3dc9-4524-b580-6e9f0c1e9782"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9773203829731114"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy(diabetes.Outcome[diabetes.Glucose >= optimal_glucose_threshold])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ehsaLMm2hCW",
        "outputId": "8b37def1-acbf-41b8-8b19-11124f8dc7f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6930190480473644"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy(diabetes.Outcome[diabetes.Glucose < optimal_glucose_threshold])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkf3nAYV2hCW"
      },
      "source": [
        "Utilizamos la implementación del árbol de decisión de sklearn para calcular la misma decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lQLczVL2hCW"
      },
      "outputs": [],
      "source": [
        "single_decision = sklearn.tree.DecisionTreeClassifier(max_depth=1, criterion = \"entropy\")\n",
        "single_decision = single_decision.fit(diabetes[[\"Glucose\", \"BMI\"]], diabetes.Outcome)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgtVoZyM2hCW"
      },
      "outputs": [],
      "source": [
        "sklearn.tree.plot_tree( # Función que nos permite visualizar el árbol de decisión ajustado.\n",
        "    single_decision, # Objeto de nuestro árbol de decisión entrenado.\n",
        "    feature_names = [\"Glucose\", \"BMI\"], # Nombres de las variables utilizadas para entrenar.\n",
        "    class_names = [\"healthy\",\"sick\"], # Nombre de las clases que estamos prediciendo.\n",
        "    label = \"all\", # Etiquetamos todas características de cada nodo.\n",
        "    proportion = True, # Visualizamos las proporciones de datos en cada nodo de decisión,\n",
        "    filled=True, # Coloreamos los nodos\n",
        "    fontsize=11, # Establecemos el tamaño de la letra del texto dentro de cada nodo.\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHTw22Jf2hCX"
      },
      "source": [
        "Preparamos el conjunto de datos para poder ajustar un árbol de decisión de mayor profundidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3g7rqCl2hCX"
      },
      "outputs": [],
      "source": [
        "diabetes_features = diabetes.iloc[:,:-1]\n",
        "diabetes_label = diabetes.Outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qNcMiQ32hCX"
      },
      "outputs": [],
      "source": [
        "(\n",
        "    diabetes_features_train, \n",
        "    diabetes_features_test, \n",
        "    diabetes_label_train, \n",
        "    diabetes_label_test\n",
        ") = sklearn.model_selection.train_test_split(\n",
        "    diabetes_features, \n",
        "    diabetes_label, \n",
        "    test_size=0.33, \n",
        "    random_state=11\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LowBLfy2hCX"
      },
      "outputs": [],
      "source": [
        "tree = sklearn.tree.DecisionTreeClassifier( # Instanciamos nuestro árbol de decisión.\n",
        "    max_depth=3, # Forzamos que nuestro árbol sólo tenga 3 niveles de profundidad.\n",
        "    criterion = \"entropy\"\n",
        "    )\n",
        "tree.fit( # Ajustamos nuestro árbol de decisión.\n",
        "    diabetes_features_train,\n",
        "    diabetes_label_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr5vt9fY2hCY"
      },
      "source": [
        "Calculamos el rendimiento de nuestro árbol de decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCLsdzxz2hCY"
      },
      "outputs": [],
      "source": [
        "print(sklearn.metrics.classification_report(\n",
        "    diabetes_label_test,\n",
        "    tree.predict(diabetes_features_test)\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALiANYcQ2hCY"
      },
      "source": [
        "Visualizamos el árbol de decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwIce3Dn2hCY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "sklearn.tree.plot_tree( # Función que nos permite visualizar el árbol de decisión ajustado.\n",
        "    tree, # Objeto de nuestro árbol de decisión entrenado.\n",
        "    feature_names = diabetes_features.columns, # Nombres de las variables utilizadas para entrenar.\n",
        "    class_names = [\"healthy\",\"sick\"], # Nombre de las clases que estamos prediciendo.\n",
        "    label = \"all\", # Etiquetamos todas características de cada nodo.\n",
        "    proportion = True, # Visualizamos las proporciones de datos en cada nodo de decisión,\n",
        "    filled=True, # Coloreamos los nodos\n",
        "    fontsize=11, # Establecemos el tamaño de la letra del texto dentro de cada nodo.\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF6PmbZy2hCZ"
      },
      "source": [
        "Un hiperparámetro que podemos ajustar en un árbol de decisión es la profundidad máxima. Visualizamos que tenemos un mejoramiento inicial del rendimiento al aumentar la profundidad, para después descender debido al sobreajuste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lINMLwjA2hCZ"
      },
      "outputs": [],
      "source": [
        "depths = range(1,10)\n",
        "performances = []\n",
        "for depth in depths:\n",
        "    current_tree = sklearn.tree.DecisionTreeClassifier( # Instanciamos nuestro árbol de decisión.\n",
        "        max_depth=depth, # Forzamos que nuestro árbol sólo tenga 3 niveles de profundidad.\n",
        "        criterion = \"entropy\"\n",
        "    )\n",
        "    roc_auc = sklearn.model_selection.cross_val_score(\n",
        "          current_tree,\n",
        "          diabetes_features, \n",
        "          diabetes_label,\n",
        "          scoring=\"roc_auc\"\n",
        "      ).mean()\n",
        "    performances.append(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs2e3Jn42hCZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(\n",
        "    depths,\n",
        "    performances\n",
        ")\n",
        "plt.xlabel(\"max_width\")\n",
        "plt.ylabel(\"mean_roc_auc_score\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}